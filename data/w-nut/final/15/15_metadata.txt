SubmissionNumber#=%=#15
FinalPaperTitle#=%=#Intrinsic evaluation of language models for code-switching
ShortPaperTitle#=%=#
NumberOfPages#=%=#6
CopyrightSigned#=%=#Hai Leong Chieu
JobTitle#==#
Organization#==#
Abstract#==#Language models used in speech recognition are often either evaluated intrinsically using perplexity on test data, or extrinsically with an automatic speech recognition (ASR) system. The former evaluation does not always correlate well with ASR performance, while the latter could be specific to particular ASR systems. Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer. Underlying such an evaluation is the assumption that the generated sentences are linguistically incorrect. In this paper, we first put this assumption into question, and observe that alternatively generated sentences could often be linguistically correct when they differ from the ground truth by only one edit. Secondly, we showed that by using multi-lingual BERT, we can achieve better performance than previous work on two code-switching data sets. Our implementation is publicly available on Github at https://github.com/sikfeng/language-modelling-for-code-switching.
Author{1}{Firstname}#=%=#Sik Feng
Author{1}{Lastname}#=%=#Cheong
Author{1}{Email}#=%=#h1710019@nushigh.edu.sg
Author{1}{Affiliation}#=%=#NUS High School of Mathematics and Science
Author{2}{Firstname}#=%=#Hai Leong
Author{2}{Lastname}#=%=#Chieu
Author{2}{Username}#=%=#chaileon
Author{2}{Email}#=%=#chaileon@dso.org.sg
Author{2}{Affiliation}#=%=#DSO National Laboratories
Author{3}{Firstname}#=%=#Jing
Author{3}{Lastname}#=%=#Lim
Author{3}{Email}#=%=#ljing2@dso.org.sg
Author{3}{Affiliation}#=%=#DSO National Laboratories

==========