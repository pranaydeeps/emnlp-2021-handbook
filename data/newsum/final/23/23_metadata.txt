SubmissionNumber#=%=#23
FinalPaperTitle#=%=#Context or No Context? A preliminary exploration of human-in-the-loop approach for Incremental Temporal Summarization in meetings
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Nicole M Beckage
JobTitle#==#
Organization#==#Intel Labs
Abstract#==#Incremental meeting temporal summarization, summarizing relevant information of partial multi-party meeting dialogue, is emerging as the next challenge in summarization research. Here we examine the extent to which human abstractive summaries of the preceding increments (context) can be combined with extractive meeting dialogue to generate abstractive summaries. We find that previous context improves ROUGE scores. Our findings further suggest that contexts begin to outweigh the dialogue. Using keyphrase extraction and semantic role labeling (SRL), we find that SRL captures relevant information without overwhelming the the model architecture. By compressing the previous contexts by ~70%, we achieve better ROUGE scores over our baseline models. Collectively, these results suggest that context matters, as does the way in which context is presented to the model.
Author{1}{Firstname}#=%=#Nicole
Author{1}{Lastname}#=%=#Beckage
Author{1}{Username}#=%=#nibe3229
Author{1}{Email}#=%=#nicole.beckage@intel.com
Author{1}{Affiliation}#=%=#Intel Labs
Author{2}{Firstname}#=%=#Shachi
Author{2}{Lastname}#=%=#H Kumar
Author{2}{Username}#=%=#shachihkumar
Author{2}{Email}#=%=#shachi.h.kumar@intel.com
Author{2}{Affiliation}#=%=#Intel Labs
Author{3}{Firstname}#=%=#Saurav
Author{3}{Lastname}#=%=#Sahay
Author{3}{Username}#=%=#sauravsahay
Author{3}{Email}#=%=#sauravsahay@gmail.com
Author{3}{Affiliation}#=%=#Intel Labs
Author{4}{Firstname}#=%=#Ramesh
Author{4}{Lastname}#=%=#Manuvinakurike
Author{4}{Username}#=%=#rameshddrr
Author{4}{Email}#=%=#ramesh.manuvinakurike@intel.com
Author{4}{Affiliation}#=%=#Intel labs

==========