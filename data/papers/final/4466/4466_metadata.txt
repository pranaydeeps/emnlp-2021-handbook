SubmissionNumber#=%=#4466
FinalPaperTitle#=%=#Fight Fire with Fire: Fine-tuning Hate Detectors using Large Samples of Generated Hate Speech
ShortPaperTitle#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#Tomer Wullach
JobTitle#==#
Organization#==#
Abstract#==#Automatic hate speech detection is hampered by the scarcity of labeled datasetd, leading to poor generalization. We employ pretrained language models (LMs) to alleviate this data bottleneck. We utilize the GPT LM for generating large amounts of synthetic hate speech sequences from available labeled examples, and leverage the generated data in fine-tuning large pretrained LMs on hate detection. An empirical study using the models of BERT, RoBERTa and ALBERT, shows that this approach improves generalization significantly and consistently within and across data distributions. In fact, we find that generating relevant labeled hate speech sequences is preferable to using out-of-domain, and sometimes also within-domain, human-labeled examples.
Author{1}{Firstname}#=%=#Tomer
Author{1}{Lastname}#=%=#Wullach
Author{1}{Username}#=%=#tomer_wullach
Author{1}{Email}#=%=#tomerwullach@gmail.com
Author{1}{Affiliation}#=%=#University of Haifa
Author{2}{Firstname}#=%=#Amir
Author{2}{Lastname}#=%=#Adler
Author{2}{Email}#=%=#adleram@mit.edu
Author{2}{Affiliation}#=%=#Braude College of Engineering and Massachusetts Institute of Technology
Author{3}{Firstname}#=%=#Einat
Author{3}{Lastname}#=%=#Minkov
Author{3}{Email}#=%=#einatm@is.haifa.ac.il
Author{3}{Affiliation}#=%=#University of Haifa

==========