SubmissionNumber#=%=#4041
FinalPaperTitle#=%=#Learning Task Sampling Policy for Multitask Learning
ShortPaperTitle#=%=#
NumberOfPages#=%=#6
CopyrightSigned#=%=#Dhanasekar Sundararaman
JobTitle#==#
Organization#==#
Abstract#==#It has been shown that training multi-task models with auxiliary tasks can improve the target task quality through cross-task transfer. However, the importance of each auxiliary task to the primary task is likely not known a priori. While the importance weights of auxiliary tasks can be manually tuned, it becomes practically infeasible with the number of tasks scaling up. To address this, we propose a search method that automatically assigns importance weights. We formulate it as a reinforcement learning problem and learn a task sampling schedule based on the evaluation accuracy of the multi-task model. Our empirical evaluation on XNLI and GLUE shows that our method outperforms uniform sampling and the corresponding single-task baseline.
Author{1}{Firstname}#=%=#Dhanasekar
Author{1}{Lastname}#=%=#Sundararaman
Author{1}{Username}#=%=#dhanasekar199531
Author{1}{Email}#=%=#ds448@duke.edu
Author{1}{Affiliation}#=%=#Duke University
Author{2}{Firstname}#=%=#Henry
Author{2}{Lastname}#=%=#Tsai
Author{2}{Username}#=%=#henrytsai_google
Author{2}{Email}#=%=#scan33scan33@gmail.com
Author{2}{Affiliation}#=%=#Google Research
Author{3}{Firstname}#=%=#Kuang-Huei
Author{3}{Lastname}#=%=#Lee
Author{3}{Username}#=%=#khlee112x
Author{3}{Email}#=%=#leekh@google.com
Author{3}{Affiliation}#=%=#Google Brain
Author{4}{Firstname}#=%=#Iulia
Author{4}{Lastname}#=%=#Turc
Author{4}{Username}#=%=#iuliaturc
Author{4}{Email}#=%=#iuliaturc@google.com
Author{4}{Affiliation}#=%=#Google Research
Author{5}{Firstname}#=%=#Lawrence
Author{5}{Lastname}#=%=#Carin
Author{5}{Username}#=%=#lcarin
Author{5}{Email}#=%=#lcarin@duke.edu
Author{5}{Affiliation}#=%=#Duke University

==========