SubmissionNumber#=%=#4048
FinalPaperTitle#=%=#Enriching and Controlling Global Semantics for Text Summarization
ShortPaperTitle#=%=#
NumberOfPages#=%=#14
CopyrightSigned#=%=#Thong Nguyen
JobTitle#==#
Organization#==#VinAI Research, Vietnam
Abstract#==#Recently, Transformer-based models have been proven effective in the abstractive summarization task by creating fluent and informative summaries. Nevertheless, these models still suffer from the short-range dependency problem, causing them to produce summaries that miss the key points of document. In this paper, we attempt to address this issue by introducing a neural topic model empowered with normalizing flow to capture the global semantics of the document, which are then integrated into the summarization model. In addition, to avoid the overwhelming effect of global semantics on contextualized representation, we introduce a mechanism to control the amount of global semantics supplied to the text generation module. Our method outperforms state-of-the-art summarization models on five common text summarization datasets, namely CNN/DailyMail, XSum, Reddit TIFU, arXiv, and PubMed.
Author{1}{Firstname}#=%=#Thong
Author{1}{Lastname}#=%=#Nguyen
Author{1}{Username}#=%=#thong.nguyenthanh5999
Author{1}{Email}#=%=#thongnguyen050999@gmail.com
Author{1}{Affiliation}#=%=#VinAI Research
Author{2}{Firstname}#=%=#Anh Tuan
Author{2}{Lastname}#=%=#Luu
Author{2}{Username}#=%=#tuanluu
Author{2}{Email}#=%=#anhtuan.luu@ntu.edu.sg
Author{2}{Affiliation}#=%=#NTU
Author{3}{Firstname}#=%=#Truc
Author{3}{Lastname}#=%=#Lu
Author{3}{Username}#=%=#lungocthientruc
Author{3}{Email}#=%=#lungocthientruc@gmail.com
Author{3}{Affiliation}#=%=#Ho Chi Minh City University of Technology
Author{4}{Firstname}#=%=#Tho
Author{4}{Lastname}#=%=#Quan
Author{4}{Username}#=%=#qttho
Author{4}{Email}#=%=#qttho@hcmut.edu.vn
Author{4}{Affiliation}#=%=#Ho Chi Minh City University of Technology

==========