SubmissionNumber#=%=#3987
FinalPaperTitle#=%=#Structure-aware Fine-tuning of Sequence-to-sequence Transformers for Transition-based AMR Parsing
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Jiawei Zhou
JobTitle#==#
Organization#==#Harvard University
Abstract#==#Predicting linearized Abstract Meaning Representation (AMR) graphs using pre-trained sequence-to-sequence Transformer models has recently led to large improvements on AMR parsing benchmarks. These parsers are simple and avoid explicit modeling of structure but lack desirable properties such as graph well-formedness guarantees or built-in graph-sentence alignments. In this work we explore the integration of general pre-trained sequence-to-sequence language models and a structure-aware transition-based approach. We depart from a pointer-based transition system and propose a simplified transition set, designed to better exploit pre-trained language models for structured fine-tuning. We also explore modeling the parser state within the pre-trained encoder-decoder architecture and different vocabulary strategies for the same purpose. We provide a detailed comparison with recent progress in AMR parsing and show that the proposed parser retains the desirable properties of previous transition-based approaches, while being simpler and reaching the new parsing state of the art for AMR 2.0, without the need for graph re-categorization.
Author{1}{Firstname}#=%=#Jiawei
Author{1}{Lastname}#=%=#Zhou
Author{1}{Username}#=%=#jzhou316
Author{1}{Email}#=%=#jzhou02@g.harvard.edu
Author{1}{Affiliation}#=%=#Harvard University
Author{2}{Firstname}#=%=#Tahira
Author{2}{Lastname}#=%=#Naseem
Author{2}{Username}#=%=#tahira
Author{2}{Email}#=%=#tahira.naseem@gmail.com
Author{2}{Affiliation}#=%=#IBM Research AI
Author{3}{Firstname}#=%=#Ram√≥n
Author{3}{Lastname}#=%=#Fernandez Astudillo
Author{3}{Username}#=%=#ramon
Author{3}{Email}#=%=#ramon@astudillo.com
Author{3}{Affiliation}#=%=#IBM Research
Author{4}{Firstname}#=%=#Young-Suk
Author{4}{Lastname}#=%=#Lee
Author{4}{Username}#=%=#ysuklee
Author{4}{Email}#=%=#ysuklee@us.ibm.com
Author{4}{Affiliation}#=%=#IBM Research
Author{5}{Firstname}#=%=#Radu
Author{5}{Lastname}#=%=#Florian
Author{5}{Username}#=%=#hansolosan
Author{5}{Email}#=%=#rflorian@cs.jhu.edu
Author{5}{Affiliation}#=%=#IBM Research
Author{6}{Firstname}#=%=#Salim
Author{6}{Lastname}#=%=#Roukos
Author{6}{Username}#=%=#roukos
Author{6}{Email}#=%=#roukos@us.ibm.com
Author{6}{Affiliation}#=%=#IBM Research AI

==========