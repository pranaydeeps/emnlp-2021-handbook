SubmissionNumber#=%=#918
FinalPaperTitle#=%=#Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Tianfu Zhang
JobTitle#==#
Organization#==#Beijing Institute of Technology, Zhongguancun No.5 Street, Beijing, China
Abstract#==#Multi-head self-attention recently attracts enormous interest owing to its specialized functions, significant parallelizable computation, and flexible extensibility. However, very recent empirical studies show that some self-attention heads make little contribution and can be pruned as redundant heads. This work takes a novel perspective of identifying and then vitalizing redundant heads. We propose a redundant head enlivening (RHE) method to precisely identify redundant heads, and then vitalize their potential by learning syntactic relations and prior knowledge in the text without sacrificing the roles of important heads. Two novel syntax-enhanced attention (SEA) mechanisms: a dependency mask bias and a relative local-phrasal position bias, are introduced to revise self-attention distributions for syntactic enhancement in machine translation. The importance of individual heads is dynamically evaluated during the redundant heads identification, on which we apply SEA to vitalize redundant heads while maintaining the strength of important heads. Experimental results on widely adopted WMT14 and WMT16 English to German and English to Czech language machine translation validate the RHE effectiveness.
Author{1}{Firstname}#=%=#Tianfu
Author{1}{Lastname}#=%=#Zhang
Author{1}{Username}#=%=#cjackztf
Author{1}{Email}#=%=#tianfuzhang@bit.edu.cn
Author{1}{Affiliation}#=%=#Beijing Institute of Technology
Author{2}{Firstname}#=%=#Heyan
Author{2}{Lastname}#=%=#Huang
Author{2}{Username}#=%=#hhy63
Author{2}{Email}#=%=#hhy63@bit.edu.cn
Author{2}{Affiliation}#=%=#Beijing Institute of Technology
Author{3}{Firstname}#=%=#Chong
Author{3}{Lastname}#=%=#Feng
Author{3}{Username}#=%=#fengchong
Author{3}{Email}#=%=#fengchong@hotmail.com
Author{3}{Affiliation}#=%=#Beijing Institute of Technology
Author{4}{Firstname}#=%=#Longbing
Author{4}{Lastname}#=%=#Cao
Author{4}{Email}#=%=#longbing.cao@uts.edu.au
Author{4}{Affiliation}#=%=#University of Technology, Sydney

==========