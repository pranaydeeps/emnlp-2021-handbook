SubmissionNumber#=%=#196
FinalPaperTitle#=%=#{UNK}s Everywhere: {A}dapting Multilingual Language Models to New Scripts
ShortPaperTitle#=%=#
NumberOfPages#=%=#18
CopyrightSigned#=%=#Jonas Pfeiffer
JobTitle#==#
Organization#==#Technical University of Darmstadt
Abstract#==#Massively multilingual language models such as multilingual BERT offer state-of-the-art cross-lingual transfer performance on a range of NLP tasks. However, due to limited capacity and large differences in pretraining data sizes, there is a profound performance gap between resource-rich and resource-poor target languages.  The ultimate challenge is dealing with under-resourced languages not covered at all by the models and written in scripts unseen during pretraining. In this work, we propose a series of novel data-efficient methods that enable quick and effective adaptation of pretrained multilingual models to such low-resource languages and unseen scripts. Relying on matrix factorization, our methods capitalize on the existing latent knowledge about multiple languages already available in the pretrained model's embedding matrix. Furthermore, we show that learning of the new dedicated embedding matrix in the target language can be improved by leveraging a small number of vocabulary items (i.e., the so-called lexically overlapping tokens) shared between mBERT's and target language vocabulary. Our adaptation techniques offer substantial performance gains for languages with unseen scripts. We also demonstrate that they can yield improvements for low-resource languages written in scripts covered by the pretrained model.
Author{1}{Firstname}#=%=#Jonas
Author{1}{Lastname}#=%=#Pfeiffer
Author{1}{Username}#=%=#jopfeiff
Author{1}{Email}#=%=#pfeiffer@ukp.informatik.tu-darmstadt.de
Author{1}{Affiliation}#=%=#TU Darmstadt
Author{2}{Firstname}#=%=#Ivan
Author{2}{Lastname}#=%=#Vulić
Author{2}{Username}#=%=#ivulic
Author{2}{Email}#=%=#iv250@cam.ac.uk
Author{2}{Affiliation}#=%=#University of Cambridge
Author{3}{Firstname}#=%=#Iryna
Author{3}{Lastname}#=%=#Gurevych
Author{3}{Username}#=%=#gurevych
Author{3}{Email}#=%=#gurevych@ukp.informatik.tu-darmstadt.de
Author{3}{Affiliation}#=%=#UKP Lab, Technische Universität Darmstadt
Author{4}{Firstname}#=%=#Sebastian
Author{4}{Lastname}#=%=#Ruder
Author{4}{Username}#=%=#sebastianruder
Author{4}{Email}#=%=#ruder.sebastian@gmail.com
Author{4}{Affiliation}#=%=#DeepMind

==========