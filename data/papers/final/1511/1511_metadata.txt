SubmissionNumber#=%=#1511
FinalPaperTitle#=%=#Char2Subword: Extending the Subword Embedding Space Using Robust Character Compositionality
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Gustavo Aguilar
JobTitle#==#
Organization#==#
Abstract#==#Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword tokenization process of language models as it provides multiple benefits. However, this process is solely based on pre-training data statistics, making it hard for the tokenizer to handle infrequent spellings. On the other hand, though robust to misspellings, pure character-level models often lead to unreasonably long sequences and make it harder for the model to learn meaningful words. To alleviate these challenges, we propose a character-based subword module (char2subword) that learns the subword embedding table in pre-trained models like BERT. Our char2subword module builds representations from characters out of the subword vocabulary, and it can be used as a drop-in replacement of the subword embedding table. The module is robust to character-level alterations such as misspellings, word inflection, casing, and punctuation. We integrate it further with BERT through pre-training while keeping BERT transformer parameters fixed--and thus, providing a practical method. Finally, we show that incorporating our module to mBERT significantly improves the performance on the social media linguistic code-switching evaluation (LinCE) benchmark.
Author{1}{Firstname}#=%=#Gustavo
Author{1}{Lastname}#=%=#Aguilar
Author{1}{Username}#=%=#gaguilar
Author{1}{Email}#=%=#gustavoaguilar91@gmail.com
Author{1}{Affiliation}#=%=#University of Houston
Author{2}{Firstname}#=%=#Bryan
Author{2}{Lastname}#=%=#McCann
Author{2}{Username}#=%=#bmccann
Author{2}{Email}#=%=#bryan.mccann.is@gmail.com
Author{2}{Affiliation}#=%=#You.com
Author{3}{Firstname}#=%=#Tong
Author{3}{Lastname}#=%=#Niu
Author{3}{Username}#=%=#mrnt0810
Author{3}{Email}#=%=#tniu@salesforce.com
Author{3}{Affiliation}#=%=#Salesforce Research
Author{4}{Firstname}#=%=#Nazneen
Author{4}{Lastname}#=%=#Rajani
Author{4}{Username}#=%=#emailnazneen
Author{4}{Email}#=%=#emailnazneen@gmail.com
Author{4}{Affiliation}#=%=#Salesforce Research
Author{5}{Firstname}#=%=#Nitish Shirish
Author{5}{Lastname}#=%=#Keskar
Author{5}{Username}#=%=#keskarnitish
Author{5}{Email}#=%=#keskar.nitish@u.northwestern.edu
Author{5}{Affiliation}#=%=#Salesforce Research
Author{6}{Firstname}#=%=#Thamar
Author{6}{Lastname}#=%=#Solorio
Author{6}{Username}#=%=#solorio
Author{6}{Email}#=%=#thamar.solorio@gmail.com
Author{6}{Affiliation}#=%=#University of Houston

==========