SubmissionNumber#=%=#3405
FinalPaperTitle#=%=#Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration
ShortPaperTitle#=%=#
NumberOfPages#=%=#15
CopyrightSigned#=%=#Shufan Wang
JobTitle#==#
Organization#==#University of Massachusetts, Amherst
Abstract#==#Phrase representations derived from BERT often do not exhibit complex phrasal compositionality, as the model relies instead on lexical similarity to determine semantic relatedness. 
In this paper, we propose a contrastive fine-tuning objective that enables BERT to produce more powerful phrase embeddings. Our approach (Phrase-BERT) relies on a dataset of diverse phrasal paraphrases, which is automatically generated using a paraphrase generation model, as well as a large-scale dataset of phrases in context mined from the Books3 corpus.
Phrase-BERT outperforms baselines across a variety of phrase-level similarity tasks, while also demonstrating increased lexical diversity between nearest neighbors in the vector space. Finally, as a case study, we show that Phrase-BERT embeddings can be easily integrated with a simple autoencoder to build a phrase-based neural topic model that interprets topics as mixtures of words and phrases by performing a nearest neighbor search in the embedding space.
Crowdsourced evaluations demonstrate that this phrase-based topic model produces more coherent and meaningful topics than baseline word and phrase-level topic models, further validating the utility of Phrase-BERT.
Author{1}{Firstname}#=%=#Shufan
Author{1}{Lastname}#=%=#Wang
Author{1}{Username}#=%=#shufanwang
Author{1}{Email}#=%=#shufanwang@umass.edu
Author{1}{Affiliation}#=%=#University of Massachusetts Amherst
Author{2}{Firstname}#=%=#Laure
Author{2}{Lastname}#=%=#Thompson
Author{2}{Username}#=%=#laurejt
Author{2}{Email}#=%=#laurejt@cs.umass.edu
Author{2}{Affiliation}#=%=#University of Massachusetts Amherst
Author{3}{Firstname}#=%=#Mohit
Author{3}{Lastname}#=%=#Iyyer
Author{3}{Username}#=%=#miyyer
Author{3}{Email}#=%=#m.iyyer@gmail.com
Author{3}{Affiliation}#=%=#University of Massachusetts Amherst

==========