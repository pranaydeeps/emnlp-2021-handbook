SubmissionNumber#=%=#1437
FinalPaperTitle#=%=#Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders
ShortPaperTitle#=%=#
NumberOfPages#=%=#18
CopyrightSigned#=%=#Fangyu Liu
JobTitle#==#
Organization#==#University of Cambridge, Cambridge, UK
Abstract#==#Previous work has indicated that pretrained Masked Language Models (MLMs) are not effective as universal lexical and sentence encoders off-the-shelf, i.e., without further task-specific fine-tuning on NLI, sentence similarity, or paraphrasing tasks using annotated task data. In this work, we demonstrate that it is possible to turn MLMs into effective lexical and sentence encoders even without any additional data, relying simply on self-supervision. We propose an extremely simple, fast, and effective contrastive learning technique, termed Mirror-BERT, which converts MLMs (e.g., BERT and RoBERTa) into such encoders in 20-30 seconds with no access to additional external knowledge. Mirror-BERT relies on identical and slightly modified string pairs as positive (i.e., synonymous) fine-tuning examples, and aims to maximise their similarity during "identity fine-tuning". We report huge gains over off-the-shelf MLMs with Mirror-BERT both in lexical-level and in sentence-level tasks, across different domains and different languages. Notably, in sentence similarity (STS) and question-answer entailment (QNLI) tasks, our self-supervised Mirror-BERT model even matches the performance of the Sentence-BERT models from prior work which rely on annotated task data. Finally, we delve deeper into the inner workings of MLMs, and suggest some evidence on why this simple Mirror-BERT fine-tuning approach can yield effective universal lexical and sentence encoders.
Author{1}{Firstname}#=%=#Fangyu
Author{1}{Lastname}#=%=#Liu
Author{1}{Username}#=%=#liugfangyu1996
Author{1}{Email}#=%=#fl399@cam.ac.uk
Author{1}{Affiliation}#=%=#University of Cambridge
Author{2}{Firstname}#=%=#Ivan
Author{2}{Lastname}#=%=#VuliÄ‡
Author{2}{Username}#=%=#ivulic
Author{2}{Email}#=%=#iv250@cam.ac.uk
Author{2}{Affiliation}#=%=#University of Cambridge
Author{3}{Firstname}#=%=#Anna
Author{3}{Lastname}#=%=#Korhonen
Author{3}{Username}#=%=#anna.korhonen
Author{3}{Email}#=%=#alk23@cam.ac.uk
Author{3}{Affiliation}#=%=#University of Cambridge
Author{4}{Firstname}#=%=#Nigel
Author{4}{Lastname}#=%=#Collier
Author{4}{Username}#=%=#collier
Author{4}{Email}#=%=#nhc30@cam.ac.uk
Author{4}{Affiliation}#=%=#University of Cambridge

==========