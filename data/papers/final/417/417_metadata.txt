SubmissionNumber#=%=#417
FinalPaperTitle#=%=#IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#24
CopyrightSigned#=%=#Samuel Cahyawijaya
JobTitle#==#
Organization#==#The Hong Kong University of Science and Technology, Hong Kong
Abstract#==#Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource---yet widely spoken---languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks---despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.
Author{1}{Firstname}#=%=#Samuel
Author{1}{Lastname}#=%=#Cahyawijaya
Author{1}{Username}#=%=#samuelc
Author{1}{Email}#=%=#scahyawijaya@connect.ust.hk
Author{1}{Affiliation}#=%=#HKUST
Author{2}{Firstname}#=%=#Genta Indra
Author{2}{Lastname}#=%=#Winata
Author{2}{Username}#=%=#giwinata
Author{2}{Email}#=%=#giwinata@connect.ust.hk
Author{2}{Affiliation}#=%=#The Hong Kong University of Science and Technology
Author{3}{Firstname}#=%=#Bryan
Author{3}{Lastname}#=%=#Wilie
Author{3}{Username}#=%=#bryanwilie
Author{3}{Email}#=%=#bryanwilie92@gmail.com
Author{3}{Affiliation}#=%=#Artificial Intelligence Center - ITB
Author{4}{Firstname}#=%=#Karissa
Author{4}{Lastname}#=%=#Vincentio
Author{4}{Username}#=%=#karissa
Author{4}{Email}#=%=#felicia.vincentio@student.umn.ac.id
Author{4}{Affiliation}#=%=#Universitas Multimedia Nusantara (Comp.Eng.)
Author{5}{Firstname}#=%=#Xiaohong
Author{5}{Lastname}#=%=#Li
Author{5}{Username}#=%=#lixiaohonglydia
Author{5}{Email}#=%=#lydiali88@yahoo.com
Author{5}{Affiliation}#=%=#Gojek
Author{6}{Firstname}#=%=#Adhiguna
Author{6}{Lastname}#=%=#Kuncoro
Author{6}{Username}#=%=#akuncoro
Author{6}{Email}#=%=#adhiguna.kuncoro@gmail.com
Author{6}{Affiliation}#=%=#University of Oxford and DeepMind
Author{7}{Firstname}#=%=#Sebastian
Author{7}{Lastname}#=%=#Ruder
Author{7}{Username}#=%=#sebastianruder
Author{7}{Email}#=%=#ruder.sebastian@gmail.com
Author{7}{Affiliation}#=%=#DeepMind
Author{8}{Firstname}#=%=#Zhi Yuan
Author{8}{Lastname}#=%=#Lim
Author{8}{Username}#=%=#zyuanlim
Author{8}{Email}#=%=#zyuanlim@gmail.com
Author{8}{Affiliation}#=%=#Gojek
Author{9}{Firstname}#=%=#Syafri
Author{9}{Lastname}#=%=#Bahar
Author{9}{Username}#=%=#syafrib
Author{9}{Email}#=%=#syafri.login@gmail.com
Author{9}{Affiliation}#=%=#Gojek
Author{10}{Firstname}#=%=#Masayu
Author{10}{Lastname}#=%=#Khodra
Author{10}{Username}#=%=#masayu
Author{10}{Email}#=%=#masayu@staff.stei.itb.ac.id
Author{10}{Affiliation}#=%=#Institut Teknologi Bandung
Author{11}{Firstname}#=%=#Ayu
Author{11}{Lastname}#=%=#Purwarianti
Author{11}{Username}#=%=#ayu
Author{11}{Email}#=%=#ayu@informatika.org
Author{11}{Affiliation}#=%=#Bandung Institute of Technology
Author{12}{Firstname}#=%=#Pascale
Author{12}{Lastname}#=%=#Fung
Author{12}{Username}#=%=#pascale
Author{12}{Email}#=%=#pascale@ece.ust.hk
Author{12}{Affiliation}#=%=#Hong Kong University of Science and Technology

==========