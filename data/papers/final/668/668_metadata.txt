SubmissionNumber#=%=#668
FinalPaperTitle#=%=#GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation
ShortPaperTitle#=%=#
NumberOfPages#=%=#14
CopyrightSigned#=%=#Derek Chen
JobTitle#==#
Organization#==#
Abstract#==#Practical dialogue systems require robust methods of detecting out-of-scope (OOS) utterances to avoid conversational breakdowns and related failure modes. Directly training a model with labeled OOS examples yields reasonable performance, but obtaining such data is a resource-intensive process.  To tackle this limited-data problem, previous methods focus on better modeling the distribution of in-scope (INS) examples. We introduce GOLD as an orthogonal technique that augments existing data to train better OOS detectors operating in low-data regimes. GOLD generates pseudo-labeled candidates using samples from an auxiliary dataset and keeps only the most beneficial candidates for training through a novel filtering mechanism. In experiments across three target benchmarks, the top GOLD model outperforms all existing methods on all key metrics, achieving relative gains of 52.4%, 48.9% and 50.3% against median baseline performance. We also analyze the unique properties of OOS data to identify key factors for optimally applying our proposed method.
Author{1}{Firstname}#=%=#Derek
Author{1}{Lastname}#=%=#Chen
Author{1}{Username}#=%=#derekchen
Author{1}{Email}#=%=#derekchen14@gmail.com
Author{1}{Affiliation}#=%=#ASAPP
Author{2}{Firstname}#=%=#Zhou
Author{2}{Lastname}#=%=#Yu
Author{2}{Username}#=%=#zhouyu
Author{2}{Email}#=%=#zhouyu@cs.columbia.edu
Author{2}{Affiliation}#=%=#Columbia University

==========