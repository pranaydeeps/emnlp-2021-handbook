SubmissionNumber#=%=#2031
FinalPaperTitle#=%=#Efficient-FedRec: Efficient Federated Learning Framework for Privacy-Preserving News Recommendation
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Jingwei Yi
JobTitle#==#
Organization#==#
Abstract#==#News recommendation is critical for personalized news access. 
Most existing news recommendation methods rely on centralized storage of users' historical news click behavior data, which may lead to privacy concerns and hazards. 
Federated Learning is a privacy-preserving framework for multiple clients to collaboratively train models without sharing their private data. 
However, the computation and communication cost of directly learning many existing news recommendation models in a federated way are unacceptable for user clients. 
In this paper, we propose an efficient federated learning framework for privacy-preserving news recommendation.
Instead of training and communicating the whole model, we decompose the news recommendation model into a large news model maintained in the server and a light-weight user model shared on both server and clients, where news representations and user model are communicated between server and clients.
More specifically, the clients request the user model and news representations from the server, and send their locally computed gradients to the server for aggregation.
The server updates its global user model with the aggregated gradients, and further updates its news model to infer updated news representations.
Since the local gradients may contain private information, we propose a secure aggregation method to aggregate gradients in a privacy-preserving way. 
Experiments on two real-world datasets show that our method can reduce the computation and communication cost on clients while keep promising model performance.
Author{1}{Firstname}#=%=#Jingwei
Author{1}{Lastname}#=%=#Yi
Author{1}{Username}#=%=#yjw1029
Author{1}{Email}#=%=#yjw1029@mail.ustc.edu.cn
Author{1}{Affiliation}#=%=#University of Science and Technology of China
Author{2}{Firstname}#=%=#Fangzhao
Author{2}{Lastname}#=%=#Wu
Author{2}{Username}#=%=#wufangzhao
Author{2}{Email}#=%=#wufangzhao@gmail.com
Author{2}{Affiliation}#=%=#Microsoft Research Asia
Author{3}{Firstname}#=%=#Chuhan
Author{3}{Lastname}#=%=#Wu
Author{3}{Username}#=%=#wuchuhan
Author{3}{Email}#=%=#wuch15@tsinghua.org.cn
Author{3}{Affiliation}#=%=#Tsinghua University
Author{4}{Firstname}#=%=#Ruixuan
Author{4}{Lastname}#=%=#Liu
Author{4}{Username}#=%=#ruixuanliu
Author{4}{Email}#=%=#ruixuan.liu@ruc.edu.cn
Author{4}{Affiliation}#=%=#Renmin University of China
Author{5}{Firstname}#=%=#Guangzhong
Author{5}{Lastname}#=%=#Sun
Author{5}{Username}#=%=#gzsun
Author{5}{Email}#=%=#gzsun@ustc.edu.cn
Author{5}{Affiliation}#=%=#University of Science and Technology of China
Author{6}{Firstname}#=%=#Xing
Author{6}{Lastname}#=%=#Xie
Author{6}{Username}#=%=#xing
Author{6}{Email}#=%=#xingx@microsoft.com
Author{6}{Affiliation}#=%=#Microsoft Research Asia

==========