SubmissionNumber#=%=#4040
FinalPaperTitle#=%=#Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Xiaochuang Han
JobTitle#==#
Organization#==#University of Washington; 185 E Stevens Way NE, Seattle, WA, USA
Abstract#==#Among the most critical limitations of deep learning NLP models are their lack of interpretability, and their reliance on spurious correlations. Prior work proposed various approaches to interpreting the black-box models to unveil the spurious correlations, but the research was primarily used in human-computer interaction scenarios. It still remains underexplored whether or how such model interpretations can be used to automatically ``unlearn'' confounding features. In this work, we propose influence tuning---a procedure that leverages model interpretations to update the model parameters towards a plausible interpretation (rather than an interpretation that relies on spurious patterns in the data) in addition to learning to predict the task labels. We show that in a controlled setup, influence tuning can help deconfounding the model from spurious patterns in data, significantly outperforming baseline methods that use adversarial training.
Author{1}{Firstname}#=%=#Xiaochuang
Author{1}{Lastname}#=%=#Han
Author{1}{Username}#=%=#xiaochuang
Author{1}{Email}#=%=#xiaochuang.han@gmail.com
Author{1}{Affiliation}#=%=#Carnegie Mellon University
Author{2}{Firstname}#=%=#Yulia
Author{2}{Lastname}#=%=#Tsvetkov
Author{2}{Username}#=%=#yulia.tsvetkov
Author{2}{Email}#=%=#yuliats@cs.washington.edu
Author{2}{Affiliation}#=%=#University of Washington

==========