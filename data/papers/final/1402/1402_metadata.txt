SubmissionNumber#=%=#1402
FinalPaperTitle#=%=#Debiasing Methods in Natural Language Understanding Make Bias More Accessible
ShortPaperTitle#=%=#
NumberOfPages#=%=#13
CopyrightSigned#=%=#Michael Mendelson
JobTitle#==#
Organization#==#Technion - Israel Institute of Technology
Haifa, 3200003
Abstract#==#Model robustness to bias is often determined by the generalization on carefully designed out-of-distribution datasets. Recent debiasing methods in natural language understanding (NLU) improve performance on such datasets by pressuring models into making unbiased predictions. An underlying assumption behind such methods is that this also leads to the discovery of more robust features in the modelâ€™s inner representations. We propose a general probing-based framework that allows for post-hoc interpretation of biases in language models, and use an information-theoretic approach to measure the extractability of certain biases from the model's representations. We experiment with several NLU datasets and known biases, and show that, counter-intuitively, the more a language model is pushed towards a debiased regime, the more bias is actually encoded in its inner representations.
Author{1}{Firstname}#=%=#Michael
Author{1}{Lastname}#=%=#Mendelson
Author{1}{Username}#=%=#mikimn
Author{1}{Email}#=%=#michael.me@campus.technion.ac.il
Author{1}{Affiliation}#=%=#Technion
Author{2}{Firstname}#=%=#Yonatan
Author{2}{Lastname}#=%=#Belinkov
Author{2}{Username}#=%=#belinkov
Author{2}{Email}#=%=#belinkov@technion.ac.il
Author{2}{Affiliation}#=%=#Technion

==========