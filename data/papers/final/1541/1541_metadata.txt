SubmissionNumber#=%=#1541
FinalPaperTitle#=%=#Connecting Attributions and QA Model Behavior on Realistic Counterfactuals
ShortPaperTitle#=%=#
NumberOfPages#=%=#17
CopyrightSigned#=%=#Xi Ye
JobTitle#==#
Organization#==#
Abstract#==#When a model attribution technique highlights a particular part of the input, a user might understand this highlight as making a statement about counterfactuals (Miller, 2019): if that part of the input were to change, the model's prediction might change as well. This paper investigates how well different attribution techniques align with this assumption on realistic counterfactuals in the case of reading comprehension (RC). RC is a particularly challenging test case, as token-level attributions that have been extensively studied in other NLP tasks such as sentiment analysis are less suitable to represent the reasoning that RC models perform. We construct counterfactual sets for three different RC settings, and through heuristics that can connect attribution methods' outputs to high-level model behavior, we can evaluate how useful different attribution methods and even different formats are for understanding counterfactuals. We find that pairwise attributions are better suited to RC than token-level attributions across these different RC settings, with our best performance coming from a modification that we propose to an existing pairwise attribution method.
Author{1}{Firstname}#=%=#Xi
Author{1}{Lastname}#=%=#Ye
Author{1}{Username}#=%=#xiye17
Author{1}{Email}#=%=#xiye17@gmail.com
Author{1}{Affiliation}#=%=#The University of Texas at Austin
Author{2}{Firstname}#=%=#Rohan
Author{2}{Lastname}#=%=#Nair
Author{2}{Username}#=%=#rnair
Author{2}{Email}#=%=#rnair@cs.utexas.edu
Author{2}{Affiliation}#=%=#University of Texas at Austin
Author{3}{Firstname}#=%=#Greg
Author{3}{Lastname}#=%=#Durrett
Author{3}{Username}#=%=#gdurrett
Author{3}{Email}#=%=#gdurrett@cs.utexas.edu
Author{3}{Affiliation}#=%=#UT Austin

==========