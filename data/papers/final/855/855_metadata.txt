SubmissionNumber#=%=#855
FinalPaperTitle#=%=#Aligning Cross-lingual Sentence Representations with Dual Momentum Contrast
ShortPaperTitle#=%=#
NumberOfPages#=%=#9
CopyrightSigned#=%=#Liang Wang
JobTitle#==#
Organization#==#
Abstract#==#In this paper, we propose to align sentence representations from different languages into a unified embedding space, where semantic similarities (both cross-lingual and monolingual) can be computed with a simple dot product. Pre-trained language models are fine-tuned with the translation ranking task. Existing work (Feng et al., 2020) uses sentences within the same batch as negatives, which can suffer from the issue of easy negatives. We adapt MoCo (He et al., 2020) to further improve the quality of alignment. As the experimental results show, the sentence representations produced by our model achieve the new state-of-the-art on several tasks, including Tatoeba en-zh similarity search (Artetxe andSchwenk, 2019b), BUCC en-zh bitext mining, and semantic textual similarity on 7 datasets.
Author{1}{Firstname}#=%=#Liang
Author{1}{Lastname}#=%=#Wang
Author{1}{Username}#=%=#bananatree
Author{1}{Email}#=%=#wangliang01@yuanfudao.com
Author{1}{Affiliation}#=%=#Yuanfudao AI Lab
Author{2}{Firstname}#=%=#Wei
Author{2}{Lastname}#=%=#Zhao
Author{2}{Username}#=%=#zhaowei8127
Author{2}{Email}#=%=#zhaowei01@yuanfudao.com
Author{2}{Affiliation}#=%=#Yuanfudao AI Lab
Author{3}{Firstname}#=%=#Jingming
Author{3}{Lastname}#=%=#Liu
Author{3}{Username}#=%=#liujingming
Author{3}{Email}#=%=#liujm@yuanfudao.com
Author{3}{Affiliation}#=%=#Yuanfudao AI Lab

==========