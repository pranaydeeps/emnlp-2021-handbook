SubmissionNumber#=%=#2752
FinalPaperTitle#=%=#{HRKD}: Hierarchical Relational Knowledge Distillation for Cross-domain Language Model Compression
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Chenhe Dong
JobTitle#==#
Organization#==#
Abstract#==#On many natural language processing tasks, large pre-trained language models (PLMs) have shown overwhelming performances compared with traditional neural network methods. Nevertheless, their huge model size and low inference speed have hindered the deployment on resource-limited devices in practice. In this paper, we target to compress PLMs with knowledge distillation, and propose a hierarchical relational knowledge distillation (HRKD) method to capture both hierarchical and domain relational information. Specifically, to enhance the model capability and transferability, we leverage the idea of meta-learning and set up domain-relational graphs to capture the relational information across different domains. And to dynamically select the most representative prototypes for each domain, we propose a hierarchical compare-aggregate mechanism to capture hierarchical relationships. Extensive experiments on public multi-domain datasets demonstrate the superior performance of our HRKD method as well as its strong few-shot learning ability. For reproducibility, we release the code at \url{https://github.com/cheneydon/hrkd}.
Author{1}{Firstname}#=%=#Chenhe
Author{1}{Lastname}#=%=#Dong
Author{1}{Username}#=%=#cheney
Author{1}{Email}#=%=#dongchh@mail2.sysu.edu.cn
Author{1}{Affiliation}#=%=#Sun Yat-sen University
Author{2}{Firstname}#=%=#Yaliang
Author{2}{Lastname}#=%=#Li
Author{2}{Username}#=%=#yaliangli
Author{2}{Email}#=%=#yaliang.li@alibaba-inc.com
Author{2}{Affiliation}#=%=#Alibaba Group
Author{3}{Firstname}#=%=#Ying
Author{3}{Lastname}#=%=#Shen
Author{3}{Username}#=%=#yingshenpku
Author{3}{Email}#=%=#sheny76@mail.sysu.edu.cn
Author{3}{Affiliation}#=%=#Sun Yat-Sen University
Author{4}{Firstname}#=%=#Minghui
Author{4}{Lastname}#=%=#Qiu
Author{4}{Username}#=%=#minghuiqiu
Author{4}{Email}#=%=#minghuiqiu@gmail.com
Author{4}{Affiliation}#=%=#Alibaba Group

==========