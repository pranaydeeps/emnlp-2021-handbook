SubmissionNumber#=%=#1
FinalPaperTitle#=%=#K-PLUG: Knowledge-injected Pre-trained Language Model for Natural Language Understanding and Generation in E-Commerce
ShortPaperTitle#=%=#
NumberOfPages#=%=#17
CopyrightSigned#=%=#Haoran Li
JobTitle#==#
Organization#==#
Abstract#==#Existing pre-trained language models (PLMs) have demonstrated the effectiveness of self-supervised learning for a broad range of natural language processing (NLP) tasks. However, most of them are not explicitly aware of domain-specific knowledge, which is essential for downstream tasks in many domains, such as tasks in e-commerce scenarios. In this paper, we propose K-PLUG, a knowledge-injected pre-trained language model based on the encoder-decoder transformer that can be transferred to both natural language understanding and generation tasks. Specifically, we propose five knowledge-aware self-supervised pre-training objectives to formulate the learning of domain-specific knowledge, including e-commerce domain-specific knowledge-bases, aspects of product entities,  categories of product entities, and unique selling propositions of product entities. We verify our method in a diverse range of e-commerce scenarios that require domain-specific knowledge, including product knowledge base completion, abstractive product summarization, and multi-turn dialogue. K-PLUG significantly outperforms baselines across the board, which demonstrates that the proposed method effectively learns a diverse set of domain-specific knowledge for both language understanding and generation tasks. Our code is available.
Author{1}{Firstname}#=%=#Song
Author{1}{Lastname}#=%=#Xu
Author{1}{Username}#=%=#xusong
Author{1}{Email}#=%=#xusong.vip@gmail.com
Author{1}{Affiliation}#=%=#JD AI research
Author{2}{Firstname}#=%=#Haoran
Author{2}{Lastname}#=%=#Li
Author{2}{Username}#=%=#hrli
Author{2}{Email}#=%=#lihaoran24@jd.com
Author{2}{Affiliation}#=%=#JD AI Research
Author{3}{Firstname}#=%=#Peng
Author{3}{Lastname}#=%=#Yuan
Author{3}{Username}#=%=#panghu
Author{3}{Email}#=%=#17181347@qq.com
Author{3}{Affiliation}#=%=#JD AI Research
Author{4}{Firstname}#=%=#Yujia
Author{4}{Lastname}#=%=#Wang
Author{4}{Username}#=%=#jessicayujia
Author{4}{Email}#=%=#yujia.wang@berkeley.edu
Author{4}{Affiliation}#=%=#University of California, Berkeley
Author{5}{Firstname}#=%=#Youzheng
Author{5}{Lastname}#=%=#Wu
Author{5}{Username}#=%=#yzwu
Author{5}{Email}#=%=#erzhengcn@gmail.com
Author{5}{Affiliation}#=%=#JD AI Research
Author{6}{Firstname}#=%=#Xiaodong
Author{6}{Lastname}#=%=#He
Author{6}{Username}#=%=#xiaohe.ai
Author{6}{Email}#=%=#xiaohe.ai@outlook.com
Author{6}{Affiliation}#=%=#JD AI Research
Author{7}{Firstname}#=%=#Ying
Author{7}{Lastname}#=%=#Liu
Author{7}{Username}#=%=#liu.ying
Author{7}{Email}#=%=#liu.ying@ruc.edu.cn
Author{7}{Affiliation}#=%=#Renmin University of China
Author{8}{Firstname}#=%=#Bowen
Author{8}{Lastname}#=%=#Zhou
Author{8}{Username}#=%=#bowenzhou
Author{8}{Email}#=%=#zhoubw@gmail.com
Author{8}{Affiliation}#=%=#JD.Com AI Research

==========