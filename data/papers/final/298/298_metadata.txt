SubmissionNumber#=%=#298
FinalPaperTitle#=%=#Unsupervised Dependency Parsing: Let's Use Supervised Parsers
ShortPaperTitle#=%=#Unsupervised Dependency Parsing: Let's Use Supervised Parsers
NumberOfPages#=%=#11
CopyrightSigned#=%=#Phong Le
JobTitle#==#
Organization#==#University of Amsterdam, the Netherlands
Abstract#==#We present a self-training approach to unsupervised dependency parsing that
reuses existing
supervised and unsupervised parsing algorithms. Our approach, called `iterated
reranking'
(IR), starts with dependency trees generated by an unsupervised parser, and
iteratively
improves these trees using the richer probability models used in supervised
parsing that
are in turn trained on these trees. Our system achieves 1.8% accuracy higher
than the state-of-the-part parser of Spitkovsky et al. (2013) on the WSJ
corpus.
Author{1}{Firstname}#=%=#Phong
Author{1}{Lastname}#=%=#Le
Author{1}{Email}#=%=#lephong.xyz@gmail.com
Author{1}{Affiliation}#=%=#University of Amsterdam
Author{2}{Firstname}#=%=#Willem
Author{2}{Lastname}#=%=#Zuidema
Author{2}{Email}#=%=#w.h.zuidema@uva.nl
Author{2}{Affiliation}#=%=#University of Amsterdam

==========