SubmissionNumber#=%=#293
FinalPaperTitle#=%=#Accurate Evaluation of Segment-level Machine Translation Metrics
ShortPaperTitle#=%=#Accurate Evaluation of Segment-level Machine Translation Metrics
NumberOfPages#=%=#9
CopyrightSigned#=%=#Yvette Graham
JobTitle#==#
Organization#==#Yvette Graham,
ADAPT Research Centre,
Trinity College Dublin,
College Green,
Dublin 2,
Ireland
Abstract#==#Evaluation of segment-level machine translation metrics is currently hampered
by: (1) low inter-annotator agreement levels in human assessments; (2) lack of
an effective mechanism for evaluation of translations of equal quality; and (3)
lack of methods of significance testing improvements over a baseline.  In this
paper, we provide solutions to each of these challenges and outline a new human
evaluation methodology aimed specifically at assessment of segment-level
metrics.  We replicate the human evaluation component of WMT-13 and reveal that
the current state-of-the-art performance of segment-level metrics is better
than previously believed.  Three segment-level metrics --- Meteor, nLepor and
sentBLEU-moses --- are found to correlate with human assessment at a level not
significantly outperformed by any other metric in both the individual language
pair assessment for Spanish to English and the aggregated set of 9 language
pairs.
Author{1}{Firstname}#=%=#Yvette
Author{1}{Lastname}#=%=#Graham
Author{1}{Email}#=%=#graham.yvette@gmail.com
Author{1}{Affiliation}#=%=#Trinity College Dublin
Author{2}{Firstname}#=%=#Timothy
Author{2}{Lastname}#=%=#Baldwin
Author{2}{Email}#=%=#tb@ldwin.net
Author{2}{Affiliation}#=%=#The University of Melbourne
Author{3}{Firstname}#=%=#Nitika
Author{3}{Lastname}#=%=#Mathur
Author{3}{Email}#=%=#nmathur@student.unimelb.edu.au
Author{3}{Affiliation}#=%=#The University of Melbourne

==========