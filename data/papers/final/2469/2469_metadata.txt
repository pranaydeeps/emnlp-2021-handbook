SubmissionNumber#=%=#2469
FinalPaperTitle#=%=#Cross-Lingual Leveled Reading Based on Language-Invariant Features
ShortPaperTitle#=%=#
NumberOfPages#=%=#6
CopyrightSigned#=%=#饶思敏
JobTitle#==#
Organization#==#
Abstract#==#Leveled reading (LR) aims to automatically classify texts by the cognitive levels of readers, which is fundamental in providing appropriate reading materials regarding different reading capabilities. However, most state-of-the-art LR methods rely on the availability of copious annotated resources, which prevents their adaptation to low-resource languages like Chinese. In our work, to tackle LR in Chinese, we explore how different language transfer methods perform on English-Chinese LR. Specifically, we focus on adversarial training and cross-lingual pre-training method to transfer the LR knowledge learned from annotated data in the resource-rich English language to Chinese. For evaluation, we first introduce the age-based standard to align datasets with different leveling standards. Then we conduct  experiments in both zero-shot and few-shot settings. Comparing these two methods, quantitative and qualitative evaluations show that the cross-lingual pre-training method effectively captures the language-invariant features between English and Chinese. We conduct analysis to propose further improvement in cross-lingual LR.
Author{1}{Firstname}#=%=#Simin
Author{1}{Lastname}#=%=#Rao
Author{1}{Username}#=%=#jacintheicon
Author{1}{Email}#=%=#18811318716@163.com
Author{1}{Affiliation}#=%=#Peking University
Author{2}{Firstname}#=%=#Hua
Author{2}{Lastname}#=%=#Zheng
Author{2}{Username}#=%=#huaz
Author{2}{Email}#=%=#zhenghua@pku.edu.cn
Author{2}{Affiliation}#=%=#Peking University
Author{3}{Firstname}#=%=#Sujian
Author{3}{Lastname}#=%=#Li
Author{3}{Username}#=%=#lisujian
Author{3}{Email}#=%=#lisujian@pku.edu.cn
Author{3}{Affiliation}#=%=#pku.edu.cn

==========