SubmissionNumber#=%=#3959
FinalPaperTitle#=%=#A Deep Decomposable Model for Disentangling Syntax and Semantics in Sentence Representation
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Dingcheng Li
JobTitle#==#Senior Research Scientist
Organization#==#Cognitive Computing Lab, Baidu Seattle
10900 NE 8th St #750, Bellevue, WA 98004
Abstract#==#Recently, disentanglement based on a generative adversarial network or a variational autoencoder has significantly advanced the performance of diverse applications in CV and NLP domains. 
Nevertheless, those models still work on coarse levels in the disentanglement of closely related properties, such as syntax and semantics in human languages. This paper introduces a deep decomposable model based on VAE to disentangle syntax and semantics by using total correlation penalties on KL divergences. Notably, we decompose the KL divergence term of the original VAE so that the generated latent variables can be separated in a more clear-cut and interpretable way. 
Experiments on benchmark datasets show that our proposed model can significantly improve the disentanglement quality between syntactic and semantic representations for semantic similarity tasks and syntactic similarity tasks.
Author{1}{Firstname}#=%=#Dingcheng
Author{1}{Lastname}#=%=#Li
Author{1}{Username}#=%=#leonleeldc
Author{1}{Email}#=%=#dingchengl@gmail.com
Author{1}{Affiliation}#=%=#Amazon Alexa AI
Author{2}{Firstname}#=%=#Hongliang
Author{2}{Lastname}#=%=#Fei
Author{2}{Username}#=%=#feihongliang0
Author{2}{Email}#=%=#feihongliang0@gmail.com
Author{2}{Affiliation}#=%=#Baidu Research
Author{3}{Firstname}#=%=#Shaogang
Author{3}{Lastname}#=%=#Ren
Author{3}{Username}#=%=#shaogangren
Author{3}{Email}#=%=#shaogangren@baidu.com
Author{3}{Affiliation}#=%=#Baidu Research, USA
Author{4}{Firstname}#=%=#Ping
Author{4}{Lastname}#=%=#Li
Author{4}{Username}#=%=#pingli98
Author{4}{Email}#=%=#liping11@baidu.com
Author{4}{Affiliation}#=%=#Baidu

==========