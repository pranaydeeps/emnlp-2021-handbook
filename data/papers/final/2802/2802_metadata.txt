SubmissionNumber#=%=#2802
FinalPaperTitle#=%=#Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods
ShortPaperTitle#=%=#
NumberOfPages#=%=#15
CopyrightSigned#=%=#Peru Bhardwaj
JobTitle#==#
Organization#==#ADAPT Centre, Trinity College Dublin
Abstract#==#Despite the widespread use of Knowledge Graph Embeddings (KGE), little is known about the security vulnerabilities that might disrupt their intended behaviour. We study data poisoning attacks against KGE models for link prediction. These attacks craft adversarial additions or deletions at training time to cause model failure at test time. To select adversarial deletions, we propose to use the model-agnostic instance attribution methods from Interpretable Machine Learning, which identify the training instances that are most influential to a neural model's predictions on test instances. We use these influential triples as adversarial deletions. We further propose a heuristic method to replace one of the two entities in each influential triple to generate adversarial additions. Our experiments show that the proposed strategies outperform the state-of-art data poisoning attacks on KGE models and improve the MRR degradation due to the attacks by up to 62% over the baselines.
Author{1}{Firstname}#=%=#Peru
Author{1}{Lastname}#=%=#Bhardwaj
Author{1}{Username}#=%=#perubhardwaj
Author{1}{Email}#=%=#bhardwap@tcd.ie
Author{1}{Affiliation}#=%=#Trinity College Dublin
Author{2}{Firstname}#=%=#John
Author{2}{Lastname}#=%=#Kelleher
Author{2}{Username}#=%=#johndkelleher
Author{2}{Email}#=%=#john.d.kelleher@tudublin.ie
Author{2}{Affiliation}#=%=#Technological University Dublin
Author{3}{Firstname}#=%=#Luca
Author{3}{Lastname}#=%=#Costabello
Author{3}{Username}#=%=#lcostabello
Author{3}{Email}#=%=#luca.costabello@accenture.com
Author{3}{Affiliation}#=%=#Accenture labs
Author{4}{Firstname}#=%=#Declan
Author{4}{Lastname}#=%=#O'Sullivan
Author{4}{Username}#=%=#declan.osullivan
Author{4}{Email}#=%=#declan.osullivan@adaptcentre.ie
Author{4}{Affiliation}#=%=#ADAPT, TCD

==========