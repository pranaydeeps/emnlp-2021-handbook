SubmissionNumber#=%=#8
FinalPaperTitle#=%=#What Makes a Scientific Paper be Accepted for Publication?
ShortPaperTitle#=%=#
NumberOfPages#=%=#17
CopyrightSigned#=%=#Panagiotis Fytas
JobTitle#==#MSc Student
Organization#==#Imperial College London
Abstract#==#Despite peer-reviewing being an essential component of academia since the 1600s, it has repeatedly received criticisms for lack of transparency and consistency. We posit that recent work in machine learning and explainable AI provide tools that enable insights into the decisions from a given peer-review process. We start by simulating the peer-review process using an ML classifier and extracting global explanations in the form of linguistic features that affect the acceptance of a scientific paper for publication on an open peer-review dataset. Second, since such global explanations do not justify causal interpretations, we propose a methodology for detecting confounding effects in natural language and generating explanations, disentangled from textual confounders, in the form of lexicons. Our proposed linguistic explanation methodology indicates the following on a case dataset of ICLR submissions: a) the organising committee follows, for the most part, the recommendations of reviewers, and b) the paper's main characteristics that led to reviewers recommending acceptance for publication are originality, clarity and substance.
Author{1}{Firstname}#=%=#Panagiotis
Author{1}{Lastname}#=%=#Fytas
Author{1}{Username}#=%=#pfytas
Author{1}{Email}#=%=#pf2418@imperial.ac.uk
Author{1}{Affiliation}#=%=#Imperial College London
Author{2}{Firstname}#=%=#Georgios
Author{2}{Lastname}#=%=#Rizos
Author{2}{Username}#=%=#georgios_rizos
Author{2}{Email}#=%=#georgios.rizos12@imperial.ac.uk
Author{2}{Affiliation}#=%=#Imperial College London
Author{3}{Firstname}#=%=#Lucia
Author{3}{Lastname}#=%=#Specia
Author{3}{Username}#=%=#l.specia
Author{3}{Email}#=%=#l.specia@imperial.ac.uk
Author{3}{Affiliation}#=%=#Imperial College London

==========