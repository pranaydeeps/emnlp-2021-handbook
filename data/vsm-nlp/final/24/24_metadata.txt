SubmissionNumber#=%=#24
FinalPaperTitle#=%=#Bilingual Word Representations with Monolingual Quality in Mind
ShortPaperTitle#=%=#Bilingual Word Representations with Monolingual Quality in Mind
NumberOfPages#=%=#9
CopyrightSigned#=%=#Thang LUong
JobTitle#==#
Organization#==#Computer Science Department, Stanford University, Stanford, CA, 94305
Abstract#==#Recent work in learning bilingual representations tend to tailor towards
achieving good performance on bilingual tasks, most often the crosslingual
document classification (CLDC) evaluation, but to the detriment of preserving
clustering structures of word representations monolingually. In this work, we
propose a joint model to learn word representations from scratch that utilizes
both the context coocurrence information through the monolingual component and
the meaning equivalent signals from the bilingual constraint. Specifically, we
extend the recently popular skipgram model to learn high quality bilingual
representations efficiently. Our learned embeddings achieve a new
state-of-the-art accuracy of 80.3 for the German to English CLDC task and a
highly competitive performance of 90.7 for the other classification direction.
At the same time, our models outperform best embeddings from past bilingual
representation work by a large margin in the monolingual word similarity
evaluation.
Author{1}{Firstname}#=%=#Thang
Author{1}{Lastname}#=%=#Luong
Author{1}{Email}#=%=#luong.m.thang@gmail.com
Author{1}{Affiliation}#=%=#Stanford University
Author{2}{Firstname}#=%=#Hieu
Author{2}{Lastname}#=%=#Pham
Author{2}{Email}#=%=#hyhieu@cs.stanford.edu
Author{2}{Affiliation}#=%=#Stanford University
Author{3}{Firstname}#=%=#Christopher D.
Author{3}{Lastname}#=%=#Manning
Author{3}{Email}#=%=#manning@cs.stanford.edu
Author{3}{Affiliation}#=%=#Stanford University

==========