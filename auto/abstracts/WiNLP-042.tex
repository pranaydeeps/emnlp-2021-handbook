In this abstract, we explore transfer learning to improve optical character recognition (OCR) post-correction, specifically for endangered language texts. We extend an existing OCR post-correction model (Rijhwani et al., 2020) by introducing an additional pretraining step on related data, such as text in a related language or available target endangered language datasets that may differ in orthography. Although cross-lingual transfer is often successful in high-resource settings, our preliminary results show that transferring from related language data decreases performance for this task. On the other hand, we observe small improvements in performance when transferring from additional target language data.
