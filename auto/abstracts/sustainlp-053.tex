In second language acquisition, assessing the readability of texts is essential for many educational applications. Hence, the development of artificial intelligence tools to automatically assess readability with little or no human supervision is required owing to the high cost of manual readability labeling by educational experts. Prior unsupervised methods reported that the readability labels correlate well with the perplexity-based scores of neural large language models, which are computationally costly. This paper proposes a novel unsupervised method that requires far less computational resources. We establish word difficulty features that accurately capture the language knowledge of second language learners by training a logistic regression model on vocabulary test results to obtain the probability that a typical language learner knows a word. This model uses no readability labels for training, and therefore is unsupervised. In the experiments, our assessor outperformed the perplexity-based assessors of large neural language models.
