This paper describes our participating system in the shared task Explainable quality estimation of 2nd Workshop on Evaluation \& Comparison of NLP Systems. The task of quality estimation (QE, a.k.a. reference-free evaluation) is to predict the quality of MT output at inference time without access to reference translations. In this proposed work, we first build a word-level quality estimation model, then we finetune this model for sentence-level QE. Our proposed models achieve near state-of-the-art results. In the word-level QE, we place 2nd and 3rd on the supervised Ro-En and Et-En test sets. In the sentence-level QE, we achieve a relative improvement of 8.86\% (Ro-En) and 10.6\% (Et-En) in terms of the Pearson correlation coefficient over the baseline model.
