Level of committed belief is a modality in natural language, it expresses a speak-er/writer's belief in a proposition. Initial work exploring this phenomenon in the literature both from a linguistic and computational modeling perspective shows that it is a chal-lenging phenomenon to capture, yet of great interest to several downstream NLP applica-tions.  In this work, we focus on identifying relevant features to the task of determining the level of committed belief tagging in two cor-pora specifically annotated for the phenome-non: the LU corpus and the Factbank corpus. We perform a thorough analysis comparing tagging schemes, infrastructure machinery, feature sets, preprocessing schemes and data genres and their impact on performance in both corpora. Our best results are an F1 score of 75.7 on the FactBank corpus and 72.9 on the smaller LU corpus.
