We examine different ensemble methods, including an oracle, to estimate the upper limit of classification accuracy for Native Language Identification (NLI). The oracle outperforms state-of-the-art systems by over 10\% and results indicate that for many misclassified texts the correct class label receives a significant portion of the ensemble votes, often being the runner-up.  We also present a pilot study of human performance for NLI, the first such experiment. While some participants achieve modest results on our simplified setup with 5 L1s, they did not outperform our NLI system, and this performance gap is likely to widen on the standard NLI setup.
