Model selection (picking, for example, the feature set and the regularization strength) is crucial for building high-accuracy NLP models. In supervised learning, we can estimate the accuracy of a model on a subset of the labeled data and choose the model with the highest accuracy. In contrast, here we focus on  type-supervised learning, which uses constraints over the possible labels for word types for supervision, with no or little labeled text. We propose a novel model selection criterion and evaluate its effectiveness on type-supervised POS-tagging in nine languages. It outperforms the standard log-likelihood-based criteria, closing 62\\% of the gap to an oracle upper bound. We also show that when a small labeled set is available, the set should be used for semi-supervised learning rather than for model selection only -- using it for model selection reduces the error by less than 2\\%, whereas using it for semi-supervised learning reduces the error by 42\\%.
