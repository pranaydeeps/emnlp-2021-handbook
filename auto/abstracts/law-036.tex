Progress in speech and language technologies has long been fueled by large-scale data resources. Semantic resources that could facilitate deeper language understanding are not, however, available on a comparable scale, and are widely assumed to require prohibitive expense and expertise to create. This paper focuses on the problem of annotating semantic frames and explores the viability of crowdsourcing for the task of frame disambiguation. We present a novel supervised crowdsourcing paradigm that incorporates insights from human computation studies, as well as experimental results demonstrating the value of feedback, interaction and other innovations designed to accommodate the relative complexity of the task. These results suggest the feasibility of developing scalable methodologies for semantic annotation tasks requiring an intermediate level of expertise.
