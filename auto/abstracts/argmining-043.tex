Summarizing a large collection of arguments by identifying only a small number of concise and semantic matching phrases and reporting how many arguments exist per phrase is known as Key Point Analysis (KPA). Recently, KPA has been mostly tackled by using transformer-based pre-trained language models such as BERT. In this paper, we introduce a siamese DistilBERT network for KPA. The siamese network improved upon a conventional BERT sequence classifier by 12.57\% in terms of strict mAP on the development dataset but suffered a performance loss of 7.02\% in terms of strict mAP on the test dataset. We find that overfitting and a high vocabulary mismatch between arguments and key points cause the performance difference.
